---
title: "Why Does Artificial Intelligence Really Make Us Anxious? A Political–Economic Reading"
description: "A structural perspective on why AI fear has less to do with algorithms and more to do with power, ownership, and economic control."
tags: ["AI", "Political Economy", "Technology", "Automation", "Society"]
pubDatetime: 2025-11-30
---

# Why Does Artificial Intelligence Really Make Us Anxious? A Political–Economic Reading

Every time someone asks me whether I think AI will replace us, I remember the answer that is repeated almost reflexively: *“AI is programmed or trained by humans.”*  
Technically true. Deeply evasive.

Because the real problem has never been **who** programs the machine.  
The problem is **what** is done with it once it’s programmed — and, more importantly, **who gets to decide**.

We have already witnessed how the internet, smartphones, digital platforms, and automation transformed entire industries. And the pattern is always the same: every time a technology dramatically increases productivity, anxiety follows. Not because the technology is “bad,” but because we live in a system where not everyone has a say in how it is used — and where the gains from increased productivity are rarely distributed equitably.

The problem was never electricity, or the steam engine, or now AI.  
The problem is that a minority concentrates more power by using technology as leverage, while the rest are left exposed to the consequences of those decisions.

If we look at the economic structure behind AI, today’s large language models — GPT, Claude, Gemini — function as **productive infrastructure**. They require massive capital: GPUs, data centers, fleets of engineers. Only a very small group can own and operate them. They are not in the hands of the Global South, nor workers, nor unions, nor cooperatives. They are controlled by billionaires, transnational corporations, and increasingly by states with authoritarian ambitions.

This is why the real question is not: *“Will AI replace me?”*  
The real question is: *“Who controls the AI that could replace me?”*

And here lies the most dangerous ideological trick. “Human” is far too broad a category. Saying that a model is controlled by a human does not mean that **you**, **I**, or the majority of people have any meaningful influence over how it is deployed.

A structural analysis makes it clear: the issue is not that AI depends on humans — but that it depends on *certain* humans. The owners of capital.

Saying *“don’t worry, a human is in control”* means nothing when that human sits at the top of an economic pyramid.  
The problem is not that AI is inhuman.  
The problem is that it is in the hands of very human actors whose interests diverge radically from ours.

